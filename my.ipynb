{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\gjj\\desktop\\py\\dinoai-main\\venv\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\gjj\\desktop\\py\\dinoai-main\\venv\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\gjj\\desktop\\py\\dinoai-main\\venv\\lib\\site-packages (from pytesseract) (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install stable-baselines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install mss pydirectinput pytesseract opencv-python numpy gym matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome://dino/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "\n",
    "# from gym import Env\n",
    "\n",
    "# from gym.spaces import Box, Discrete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWebGame\u001b[39;00m(\u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mEnv):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "class WebGame(gym.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,100))\n",
    "        self.action_space = Discrete(3)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top': 240, 'left': 655, 'width': 150, 'height': 75}\n",
    "        self.done_location = {'top': 190, 'left': 860, 'width': 100, 'height': 30}\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0:'space',\n",
    "            1: 'down', \n",
    "            2: 'no_op'\n",
    "\n",
    "        }\n",
    "        if action !=2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        done, done_cap = self.get_done() \n",
    "        observation = self.get_observation()\n",
    "        reward = 1 \n",
    "        info = {}\n",
    "        return observation, reward, done, info\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation()\n",
    "        \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', self.current_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "         \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (100,83))\n",
    "        channel = np.reshape(resized, (1,83,100))\n",
    "        return channel\n",
    "    \n",
    "    def get_done(self):\n",
    "        done_cap = np.array(self.cap.grab(self.done_location))\n",
    "        done_strings = ['GAME', 'GAHE']\n",
    "        done=False\n",
    "        # if np.sum(done_cap) < 44300000:\n",
    "        #     done = True\n",
    "        done = False\n",
    "        res = pytesseract.image_to_string(done_cap)[:4]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "        return done, done_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs=env.get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1da0409b490>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "done, done_cap = env.get_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1da06dfb190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(done_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GAME'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytesseract.image_to_string(done_cap)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 0 is 8\n",
      "Total Reward for episode 1 is 9\n",
      "Total Reward for episode 2 is 11\n",
      "Total Reward for episode 3 is 11\n",
      "Total Reward for episode 4 is 12\n",
      "Total Reward for episode 5 is 9\n",
      "Total Reward for episode 6 is 10\n",
      "Total Reward for episode 7 is 13\n",
      "Total Reward for episode 8 is 9\n",
      "Total Reward for episode 9 is 9\n"
     ]
    }
   ],
   "source": [
    "for episode in range(10): \n",
    "    obs = env.reset()\n",
    "    done = False  \n",
    "    total_reward   = 0\n",
    "    while not done: \n",
    "        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "        total_reward  += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'check_env' from 'stable_baselines3.common.envs' (c:\\Users\\GJJ\\miniconda3\\envs\\DINO\\lib\\site-packages\\stable_baselines3\\common\\envs\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Import Base Callback for saving models\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#from stable_baselines3.common.callbacks import BaseCallback\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_env\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check Environment    \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'check_env' from 'stable_baselines3.common.envs' (c:\\Users\\GJJ\\miniconda3\\envs\\DINO\\lib\\site-packages\\stable_baselines3\\common\\envs\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "#from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.envs import check_env\n",
    "# Check Environment    \n",
    "import stable_baselines3.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv_checker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:409\u001b[0m, in \u001b[0;36mcheck_env\u001b[1;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_env\u001b[39m(env: gym\u001b[38;5;241m.\u001b[39mEnv, warn: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, skip_render_check: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    395\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    Check that an environment follows Gym API.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    This is particularly useful when using a custom environment.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m        True by default (useful for the CI)\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    410\u001b[0m         env, gym\u001b[38;5;241m.\u001b[39mEnv\n\u001b[0;32m    411\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;66;03m# ============= Check the spaces (observation and action) ================\u001b[39;00m\n\u001b[0;32m    414\u001b[0m     _check_spaces(env)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/"
     ]
    }
   ],
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 7.97GB > 2.96GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "You should use NatureCNN only with images not with Box(0.0, 255.0, (1, 83, 100), float32)\n(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\nIf you are using a custom environment,\nplease check it using our env checker:\nhttps://stable-baselines3.readthedocs.io/en/master/common/env_checker.html.\nIf you are using `VecNormalize` or already normalized channel-first images you should pass `normalize_images=False`: \nhttps://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCnnPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOG_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:141\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:144\u001b[0m, in \u001b[0;36mDQN._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_setup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_aliases()\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# Copy running stats, see GH issue #996\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:199\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m         replay_buffer_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer_class(\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size,\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreplay_buffer_kwargs,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Convert train freq parameter to TrainFreq object\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\policies.py:248\u001b[0m, in \u001b[0;36mCnnPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    237\u001b[0m     observation_space: spaces\u001b[38;5;241m.\u001b[39mSpace,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m     optimizer_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    247\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\policies.py:151\u001b[0m, in \u001b[0;36mDQNPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, features_extractor_class, features_extractor_kwargs, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn \u001b[38;5;241m=\u001b[39m activation_fn\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation_space\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_space\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize_images\u001b[39m\u001b[38;5;124m\"\u001b[39m: normalize_images,\n\u001b[0;32m    149\u001b[0m }\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\policies.py:163\u001b[0m, in \u001b[0;36mDQNPolicy._build\u001b[1;34m(self, lr_schedule)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr_schedule: Schedule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    Create the network and the optimizer.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m        lr_schedule(1) is the initial learning rate\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_q_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_q_net()\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net_target\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\policies.py:177\u001b[0m, in \u001b[0;36mDQNPolicy.make_q_net\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_q_net\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QNetwork:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# Make sure we always have separate networks for features extractors etc\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     net_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QNetwork(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnet_args)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:114\u001b[0m, in \u001b[0;36mBaseModel._update_features_extractor\u001b[1;34m(self, net_kwargs, features_extractor)\u001b[0m\n\u001b[0;32m    111\u001b[0m net_kwargs \u001b[38;5;241m=\u001b[39m net_kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# The features extractor is not shared, create a new one\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     features_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_features_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m net_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(features_extractor\u001b[38;5;241m=\u001b[39mfeatures_extractor, features_dim\u001b[38;5;241m=\u001b[39mfeatures_extractor\u001b[38;5;241m.\u001b[39mfeatures_dim))\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net_kwargs\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:120\u001b[0m, in \u001b[0;36mBaseModel.make_features_extractor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_features_extractor\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseFeaturesExtractor:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to create a features extractor.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GJJ\\Desktop\\py\\DinoAI-main\\venv\\Lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:77\u001b[0m, in \u001b[0;36mNatureCNN.__init__\u001b[1;34m(self, observation_space, features_dim, normalized_image)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(observation_space, features_dim)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# We assume CxHxW images (channels first)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Re-ordering will be done by pre-preprocessing or wrapper\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_image_space(observation_space, check_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, normalized_image\u001b[38;5;241m=\u001b[39mnormalized_image), (\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should use NatureCNN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly with images not with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are using a custom environment,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease check it using our env checker:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://stable-baselines3.readthedocs.io/en/master/common/env_checker.html.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are using `VecNormalize` or already normalized channel-first images \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou should pass `normalize_images=False`: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     88\u001b[0m n_input_channels \u001b[38;5;241m=\u001b[39m observation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     90\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(n_input_channels, \u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     91\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     97\u001b[0m )\n",
      "\u001b[1;31mAssertionError\u001b[0m: You should use NatureCNN only with images not with Box(0.0, 255.0, (1, 83, 100), float32)\n(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\nIf you are using a custom environment,\nplease check it using our env checker:\nhttps://stable-baselines3.readthedocs.io/en/master/common/env_checker.html.\nIf you are using `VecNormalize` or already normalized channel-first images you should pass `normalize_images=False`: \nhttps://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=120000, learning_starts=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, callback\u001b[38;5;241m=\u001b[39mcallback)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=10, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[181], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load('best_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[182], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done: \n\u001b[1;32m----> 6\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[0;32m      7\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(action))\n\u001b[0;32m      8\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
